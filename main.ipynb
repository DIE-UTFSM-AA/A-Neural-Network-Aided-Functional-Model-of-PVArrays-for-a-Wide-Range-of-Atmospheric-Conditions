{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, copy, csv, time\n",
    "project_path = os.getcwd()\n",
    "\n",
    "src_path  = os.path.join(project_path, 'src')\n",
    "assert os.path.exists(src_path) and os.path.isdir(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "from src.special import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DataSet:\n",
    "  url_bbdd = \"https://datahub.duramat.org/dataset/e024ad97-f724-476c-8712-797a5b213cdb/resource/87d2133e-b2d5-4282-a899-9b6f5aa23d38/download/data-for-validating-models.zip\"\n",
    "  zip_file_name = 'Data_For_Validating_Models.zip'\n",
    "  \n",
    "\n",
    "  def __init__(self, project_path):\n",
    "    data_path  = os.path.join(project_path, 'data')\n",
    "    if not all([os.path.exists(data_path), os.path.isdir(data_path)]):\n",
    "      os.makedirs(data_path)\n",
    "\n",
    "  def download(self, save_path):\n",
    "    with urllib.request.urlopen(self.url_bbdd) as dl_file:\n",
    "      with open(save_path, 'wb') as out_file:\n",
    "        out_file.write(dl_file.read())\n",
    "\n",
    "\n",
    "  def __call__(self):\n",
    "    print('a')\n",
    "\n",
    "  def unzipping(self):\n",
    "    print('a')\n",
    "  \n",
    "  def read(self):\n",
    "    print('a')\n",
    "\n",
    "  def read(self):\n",
    "    print('a')\n",
    "\n",
    "  def load(self):\n",
    "    print('a')\n",
    "\n",
    "  def save(self):\n",
    "    print('a')\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "download_url(os.path.join(data_path, 'Data_For_Validating_Models.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSetClass:\n",
    "  def __init__(self, Modules, ModelParams, path):\n",
    "    self.Path = path\n",
    "    self.Data = {}\n",
    "    self.PVModuleParams = {}\n",
    "    self.DataSet = {}\n",
    "    # for PVModule in Modules:\n",
    "    #   DataPath = normpath(self.Path,PVModule)\n",
    "    #   try: \n",
    "    #     df = pd.concat([pd.read_csv(normpath(DataPath,'Cocoa_'+PVModule+'.zip'), compression='zip'),\n",
    "    #                     pd.read_csv(normpath(DataPath,'Eugene_'+PVModule+'.zip'), compression='zip')\n",
    "    #                     ], ignore_index=True)\n",
    "    #   except: \n",
    "    #     df  = pd.read_csv(normpath(DataPath,'Golden_'+PVModule+'.csv'))\n",
    "    #   TimeSeries = df.drop(df.columns[np.arange(0, 41)], axis=1)\n",
    "    #   df.drop(df.columns[np.append([2, 4, 6,  8, 10, 12], np.arange(14, df.shape[1]))], axis=1, inplace=True)\n",
    "    #   df.rename(columns={k:['Time', 'Irradiance (W/m2)', 'Temperature (Â°C)'][n] for n,k in enumerate(df.columns[:3])}, inplace=True)\n",
    "    #   self.Data[PVModule] = {'df':df, 'TimeSeries':TimeSeries}\n",
    "    #   try:\n",
    "    #     self.DataSet[PVModule] = self.CreateDataSet(PVModule)\n",
    "    #   except:pass\n",
    "    #   try:\n",
    "    #     params = {}\n",
    "    #     models = ModelParams[ModelParams.Module==PVModule]\n",
    "    #     for k in models[ModelParams.columns[1]]:\n",
    "    #       PVmodel = models[(models[ModelParams.columns[1]]==k)&(models[ModelParams.columns[3:8]]>=0).apply(np.prod, axis=1).astype(bool)].to_dict('records')[0]\n",
    "    #       PVmodel = {k.replace(' ', ''):PVmodel[k]  for k in PVmodel}\n",
    "    #       if   k == 5:  PVmodel['name'], PVmodel['label'] = 'De Soto', 'DS'\n",
    "    #       elif k == 6:  PVmodel['name'], PVmodel['label'] = 'Dobos', 'D'\n",
    "    #       elif k == 7:  PVmodel['name'], PVmodel['label'] = 'Boyd', 'B'\n",
    "    #       elif k == 11: PVmodel['name'], PVmodel['label'] = 'Proposed', 'P'\n",
    "    #       params[k] = PVmodel\n",
    "    #     self.PVModuleParams[PVModule] = params\n",
    "    #   except:pass\n",
    "      \n",
    "  def CreateDataSet(self, PVModule, seed=123, DataSet=[70, 20, 10], Nday=5):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    df = self.Data[PVModule]['df']\n",
    "    days = df[df.columns[0]].str.split('T').str[0]\n",
    "    daysT = days.unique()[np.random.randint(days.unique().size, size=Nday)]\n",
    "    for k in range(Nday):\n",
    "      if not(k): dayP, idxPlot, DataPlot = (days==daysT[int(0)]).to_numpy(), [], []\n",
    "      else: dayP = np.logical_or(dayP,(days==daysT[int(k)]).to_numpy())\n",
    "      DataPlot.append([\n",
    "          df[days==daysT[int(k)]][df.columns[[1,2]]].to_numpy(dtype='float32'),\n",
    "          df[days==daysT[int(k)]][df.columns[np.arange(3, df.shape[1])]].to_numpy(dtype='float32'),\n",
    "          df[days==daysT[int(k)]][df.columns[0]].str.split('T').str[1].str[:-3].to_numpy()])\n",
    "      idxPlot += df[days==daysT[int(k)]].index.values.tolist()\n",
    "      if not(k): xx, yy = DataPlot[-1][0], DataPlot[-1][1]\n",
    "      else: xx, yy = np.vstack([xx, DataPlot[-1][0]]), np.vstack([yy, DataPlot[-1][1]])\n",
    "    df = df.iloc[np.logical_not(dayP)]\n",
    "    X, Y = [df[df.columns[k]] for k in [[1,2], np.arange(3, df.shape[1])]]\n",
    "    ridxs = tf.random.shuffle(tf.range(X.shape[0]))\n",
    "    X, Y = [pd.DataFrame(tf.gather(k, ridxs).numpy().astype(np.float32)) for k in [X, Y]]\n",
    "    X_tr,  X_tst, Y_tr,  Y_tst = train_test_split(X, Y, test_size=sum(DataSet[1:3])/sum(DataSet), random_state=seed)\n",
    "    X_tst, X_val, Y_tst, Y_val = train_test_split(X_tst, Y_tst, test_size=DataSet[1]/sum(DataSet[1:3]), random_state=seed)\n",
    "    idxTest = idxPlot + Y_tst.index.values.tolist()\n",
    "    X, X_tr, X_val, X_tst = [k.to_numpy(dtype='float32') for k in [X, X_tr, X_val, X_tst]]\n",
    "    Y, Y_tr, Y_val, Y_tst = [k.to_numpy(dtype='float32') for k in [Y, Y_tr, Y_val, Y_tst]]\n",
    "    X_tst, Y_tst = [np.vstack(k).astype(np.float32) for k in [[xx, X_tst], [yy, Y_tst]]]\n",
    "    return [X, X_tr, X_val, X_tst, Y, Y_tr, Y_val, Y_tst, DataPlot, idxTest]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dadfa6c9e495656b5aeef62e855dddced6b3b09cd40b0d573233c49f51a8556"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
